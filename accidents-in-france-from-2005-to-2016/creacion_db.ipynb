{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preguntas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ¿Qué relaciones existen entre la edad de los peatones su localización/acción cuando ocurrió el accidente?\n",
    "\n",
    "* Compare la relación entre género y razones de viaje.\n",
    "\n",
    "* ¿Cómo influye el equipamiento de seguridad en la gravedad del accidente?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import happybase\n",
    "from pprint import pprint\n",
    "from datetime import date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def reconect():\n",
    "    global connection\n",
    "    try:\n",
    "        connection.tables()\n",
    "    except:\n",
    "        connection = happybase.Connection('localhost')\n",
    "        connection.open()\n",
    "        print(\"reconected\\n\")\n",
    "        \n",
    "def create_table(name, dict_families):\n",
    "    if name.encode('UTF-8') in connection.tables():\n",
    "        connection.delete_table(name.encode('UTF-8'), True)\n",
    "    connection.create_table(\n",
    "        name,\n",
    "        dict_families\n",
    "    )\n",
    "        \n",
    "def drop_database():\n",
    "    for table in connection.tables():\n",
    "        connection.delete_table(table, True)\n",
    "        print(table,\"droped\")\n",
    "    print(\"database drop complete\\n\")\n",
    "\n",
    "def add_family_data(table, row_key, column_family, column_names, values):\n",
    "    column_data = {}\n",
    "    row_key = row_key.encode('UTF-8')\n",
    "    for i in range(len(column_names)):\n",
    "        column = (column_family+':'+column_names[i]).encode('UTF-8')\n",
    "        value = values[i].encode('UTF-8')\n",
    "        column_data[column] = value\n",
    "\n",
    "    table.put(row_key, column_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creacion de tablas iniciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'actions_location' droped\n",
      "b'enviromental_relevance' droped\n",
      "b'safety_consequences' droped\n",
      "database drop complete\n",
      "\n",
      "[b'actions_location', b'enviromental_relevance', b'safety_consequences']\n"
     ]
    }
   ],
   "source": [
    "reconect()\n",
    "\n",
    "drop_database()\n",
    "\n",
    "create_table('actions_location', {'User': dict(), 'Situational': dict(), 'Date': dict()})\n",
    "create_table('safety_consequences', {'Severity': dict(), 'Situational': dict(), 'User': dict(), 'Date': dict()})\n",
    "create_table('enviromental_relevance', {'Enviroment': dict(), 'Place': dict(), 'Severity': dict()})\n",
    "\n",
    "print(connection.tables())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ultra Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconected\n",
      "\n",
      "b'0' {b'User:age': b'15', b'User:sex': b'Male'}\n",
      "b'1' {b'User:age': b'33', b'User:sex': b'Female'}\n"
     ]
    }
   ],
   "source": [
    "ultratable = {}\n",
    "f = open(\"UltraTable.csv\")\n",
    "items = f.readline().replace(\"\\\"\",\"\").replace(\"\\n\",\"\").replace(\"\\ufeff\",\"\").split(\",\")\n",
    "items_lenght = len(items)\n",
    "for item in items:\n",
    "    ultratable[item] = []\n",
    "# print(users)\n",
    "\n",
    "reconect()\n",
    "actions_location_table = connection.table(b'actions_location')\n",
    "safety_consequences_table = connection.table(b'safety_consequences')\n",
    "enviromental_relevance_table = connection.table(b'enviromental_relevance')\n",
    "\n",
    "for i in range(2):\n",
    "    data = f.readline().replace(\"\\\"\",\"\").replace(\"\\n\",\"\").split(\",\")\n",
    "    dict_data = dict(zip(items, data))\n",
    "#     pprint(dict_data)\n",
    "#     print(\"\")\n",
    "    \n",
    "    timestamp = '20'+dict_data['an'].zfill(2)+dict_data['mois'].zfill(2)+dict_data['jour'].zfill(2)+dict_data['hrmn']\n",
    "  \n",
    "    days_in_year = 365.2425\n",
    "    accident_date = date(int('20'+dict_data['an'].zfill(2)), int(dict_data['mois']), int(dict_data['jour']))\n",
    "    bdsplit = dict_data['year_on'].split(\"-\")\n",
    "    birth_date = date(int(bdsplit[2]), int(bdsplit[1]), int(bdsplit[0]))\n",
    "    age = int((accident_date - birth_date).days / days_in_year)\n",
    "    \n",
    "    add_family_data(actions_location_table, \n",
    "                    str(i), \n",
    "                    'User',\n",
    "                    ['sex', 'age'],\n",
    "                    [dict_data['sexe'], str(age)])\n",
    "\n",
    "f.close()\n",
    "\n",
    "for key, data in actions_location_table.scan():\n",
    "    print(key, data)\n",
    "\n",
    "# users_dumps = json.dumps(users)\n",
    "# f = open(\"users_cleaned.json\",\"w\")\n",
    "# f.write(users_dumps)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
